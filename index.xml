<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ibiza</title><link>http://kimmj.github.io/</link><description>Recent content on Ibiza</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 08 Jan 2020 01:00:14 +0900</lastBuildDate><atom:link href="http://kimmj.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Jenkins Install</title><link>http://kimmj.github.io/jenkins/install/</link><pubDate>Tue, 11 Feb 2020 17:20:41 +0900</pubDate><guid>http://kimmj.github.io/jenkins/install/</guid><description>Configure docker-compose.yaml 다음과 같이 docker-compose.yaml 파일을 적절한 디렉토리에 생성합니다.
version: &amp;#39;2&amp;#39; services: jenkins: image: &amp;#39;jenkins/jenkins:lts&amp;#39; ports: - &amp;#39;38080:8080&amp;#39; - &amp;#39;38443:8443&amp;#39; - &amp;#39;50000:50000&amp;#39; volumes: - &amp;#39;jenkins_data:/var/jenkins_home&amp;#39; volumes: jenkins_data: driver: local driver_opts: type: none device: $PWD/jenkins_data o: bind jenkins_data는 jenkins가 사용할 데이터들입니다. 이를 local에 폴더로 만들어줍니다.
mkdir jenkins_data Start Jenkins 이제 docker-compose 명령어를 통해 실행합니다.
sudo docker-compose up -d http://$IP:38080 으로 접속할 수 있습니다. 로컬에 설치하셨다면 http://localhost:38080으로 접속하면 됩니다.
Jenkins 세팅 처음에 다음과 같은 화면을 볼 수 있습니다.</description></item><item><title>Install Prometheus</title><link>http://kimmj.github.io/prometheus/install/</link><pubDate>Thu, 30 Jan 2020 18:00:24 +0900</pubDate><guid>http://kimmj.github.io/prometheus/install/</guid><description>Prometheus Prometheus는 opensource monitoring system입니다. 음악을 하는 사람들이 많이 이용하는 사이트인 SoundCloud에서 개발된 오픈소스입니다.
PromQL이라는 Query문을 사용하여 metric을 수집할 수 있습니다. 자세한 내용은 나중에 따로 포스트를 작성하도록 하겠습니다.
이 문서에서는 docker-compose를 통해 간단하게 prometheus를 설치해볼 것입니다. 또한 prometheus와 뗄레야 뗄 수 없는 단짝 Grafana도 함께 설치할 것입니다.
Prometheus의 설치 제가 docker-compose를 선호하는 이유는 너무나도 간단하게, dependency가 있는 어플리케이션을 설치할 수 있기 때문입니다. 아래에 예시에서도 잘 드러나있습니다.
저는 monitoring/ 폴더 아래에 docker-compose.</description></item><item><title>Overview</title><link>http://kimmj.github.io/spinnaker/installation/overview/</link><pubDate>Fri, 10 Jan 2020 01:02:39 +0900</pubDate><guid>http://kimmj.github.io/spinnaker/installation/overview/</guid><description>Overview of install Spinnaker 어떻게 Spinnaker를 설치 및 배포하는지 알아보도록 하겠습니다.
가장 먼저 최소 사양을 확인해보도록 하겠습니다.
링크 : https://www.spinnaker.io/guides/developer/getting-set-up/#system-requirements
램 18 GB CPU 4코어 Ubuntu 14.04, 16.04, 18.04 Spinnaker 자체가 클라우드 환경에만 배포가 가능하기 때문에, 아마도 &amp;ldquo;전체 클라우드를 합하여 저정도면 된다&amp;quot;를 의미하는 것 같습니다.
설치 방법은 두가지로 나뉩니다.
테스트를 목적으로 Helm Chart를 통한 설치 실제로 사용할 목적으로 halyard를 통한 설치 저는 여기서 2번 halyard를 통한 설치를 해보려고 합니다.</description></item><item><title>Install Halyard</title><link>http://kimmj.github.io/spinnaker/installation/install-halyard/</link><pubDate>Sat, 11 Jan 2020 01:41:08 +0900</pubDate><guid>http://kimmj.github.io/spinnaker/installation/install-halyard/</guid><description>halyard란? halyard는 Spinnaker를 배포할 때 사용하는 CLI 툴입니다.
halyard는 Spinnaker 관련 설정들의 validation, 배포한 환경 백업, 설정 추가 및 변경에 사용됩니다.
설치 방법 선택하기 총 2가지 방법으로 halyard를 설치할 수 있습니다.
Debian/Ubuntu나 macOS에 직접 설치하기 Docker 사용하기 Spinnaker Docs에서는 실제 Production 환경이라면 직접 설치하는 방법을, 그게 아니라 간단하게 사용하려면 docker를 사용해도 된다고 하고 있습니다.
그리고 한가지의 옵션이 더 있습니다.
인터넷이 되지 않는 환경 (프록시나 방화벽 등으로 halyard를 통한 설치가 어려운 경우) 이 글을 작성하고 있는 환경은 인터넷이 잘 되는 환경입니다.</description></item><item><title>Choose Cloud Providers</title><link>http://kimmj.github.io/spinnaker/installation/choose-cloud-providers/</link><pubDate>Sun, 19 Jan 2020 00:32:21 +0900</pubDate><guid>http://kimmj.github.io/spinnaker/installation/choose-cloud-providers/</guid><description>Spinnaker를 배포할 환경을 설정해 주어야 합니다. 여기에서는 제가 구축한 local kubernetes cluster를 사용할 것입니다.
먼저 2가지가 필요합니다.
kubeconfig 파일 kubeconfig 파일은 일반적으로 ~$HOME/.kube/config 파일을 의미합니다. 저는 local kubernetes cluster로 이동하여 해당 파일을 halyard를 위한 vm으로 복사하였습니다. kubectl CLI 툴 이제 hal config 명령어를 통해 kubernetes cluster를 추가합니다.
hal config provider kubernetes enable CONTEXT=$(kubectl config current-context) hal config provider kubernetes account add wonderland \ --provider-version v2 \ --context $CONTEXT hal config features edit --artifacts true</description></item><item><title>Choose Your Environment</title><link>http://kimmj.github.io/spinnaker/installation/choose-your-environment/</link><pubDate>Sun, 19 Jan 2020 00:42:56 +0900</pubDate><guid>http://kimmj.github.io/spinnaker/installation/choose-your-environment/</guid><description>Spinnaker를 배포하는 방법에는 3가지가 있습니다. Kubernetes 환경에 배포하기, local debian으로 배포하기, local git으로 배포하기가 있습니다.
여기에서는 Kubernetes 환경에 배포하기를 진행할 것입니다.
ACCOUNT=wonderland hal config deploy edit --type distributed --account-name $ACCOUNT 위와같이 설정하면 됩니다. ACCOUNT는 kubernetes cluster를 추가할 때 사용했던 이름을 사용하면 됩니다.</description></item><item><title>Controllers Overview</title><link>http://kimmj.github.io/kubernetes/concepts/controllers-overview/</link><pubDate>Thu, 30 Jan 2020 18:26:04 +0900</pubDate><guid>http://kimmj.github.io/kubernetes/concepts/controllers-overview/</guid><description>Contents 이 포스트에서는 Kubernetes의 Controller들에 대해서 알아보도록 하겠습니다. 가장 작은 단위인 Container부터, 상위 개념인 Deployment, StatefulSet까지 다루어 보도록 하겠습니다.
Containers Pods ReplicaSets Deployments StatefulSets Monolithic vs. Microservice 우선 Monolithic과 Microservice에 대해서 짚고 넘어가도록 하겠습니다.
Monolithic의 개념은 하나의 큰 어플리케이션을 말합니다. 여러 사람이 개발을 하고 나서 하나의 큰 패키지로 빌드하고 이를 배포하죠. 간단한 서비스라면 문제가 발생하지는 않겠지만, 점점 코드의 수가 늘어나고 거대해질 수록 문제점이 생깁니다. 예를 들면 빌드시간이 오래걸린다던지, scale-out을 하기 힘들다던지 하는 문제가 있겠네요.</description></item><item><title>Choose a Storage Service</title><link>http://kimmj.github.io/spinnaker/installation/choose-a-storage-service/</link><pubDate>Sun, 19 Jan 2020 00:46:44 +0900</pubDate><guid>http://kimmj.github.io/spinnaker/installation/choose-a-storage-service/</guid><description>Spinnaker들의 데이터를 저장할 공간입니다.
여러가지 옵션들이 있지만, 저는 local로 운용할 수 있는 minio를 통해 데이터를 저장해 볼 것입니다.
minio를 docker-compose를 통해 쉽게 배포하도록 할 것입니다. 먼저, docker-compose를 설치합니다.
sudo curl -L &amp;#34;https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)&amp;#34; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose 그 뒤 minio의 docker-compose.yaml을 만듭니다.
version: '3.7' services: minio: image: minio/minio:RELEASE.2020-01-16T22-40-29Z volumes: - ./data:/data ports: - &amp;quot;9000:9000&amp;quot; environment: MINIO_ACCESS_KEY: minio MINIO_SECRET_KEY: minio123 command: server /data healthcheck: test: [&amp;quot;CMD&amp;quot;, &amp;quot;curl&amp;quot;, &amp;quot;-f&amp;quot;, &amp;quot;http://localhost:9000/minio/health/live&amp;quot;] interval: 30s timeout: 20s retries: 3 docker-compose를 통해서 deamon으로 실행합니다.</description></item><item><title>Deploy and Connect</title><link>http://kimmj.github.io/spinnaker/installation/deploy-and-connect/</link><pubDate>Sun, 19 Jan 2020 01:20:12 +0900</pubDate><guid>http://kimmj.github.io/spinnaker/installation/deploy-and-connect/</guid><description>드디어 마지막 절차입니다.
먼저 어떤 버전을 설치할지 확인후 설정합니다.
hal version list 작성 기준으로 최신 버전이 1.17.6이므로 이를 설정합니다.
hal config version edit --version 1.17.6 halyard를 NodePort로 노출시키기 위해 api와 ui에 base url을 부여합니다.
hal config security ui edit --override-base-url http://192.168.8.22:30100 hal config security api edit --override-base-url http://192.168.8.22:30200 이제 본격적으로 deploy를 하도록 합니다.
hal deploy apply 그 후 Spinnaker를 NodePort로 서비스합니다.
kubectl patch svc spin-deck -n spinnaker --type=&amp;#39;json&amp;#39; -p &amp;#39;[{&amp;#34;op&amp;#34;:&amp;#34;replace&amp;#34;,&amp;#34;path&amp;#34;:&amp;#34;/spec/type&amp;#34;,&amp;#34;value&amp;#34;:&amp;#34;NodePort&amp;#34;}]&amp;#39; kubectl patch svc spin-gate -n spinnaker --type=&amp;#39;json&amp;#39; -p &amp;#39;[{&amp;#34;op&amp;#34;:&amp;#34;replace&amp;#34;,&amp;#34;path&amp;#34;:&amp;#34;/spec/type&amp;#34;,&amp;#34;value&amp;#34;:&amp;#34;NodePort&amp;#34;}]&amp;#39; kubectl patch svc spin-deck -n spinnaker --type=&amp;#39;json&amp;#39; -p &amp;#39;[{&amp;#34;op&amp;#34;:&amp;#34;replace&amp;#34;,&amp;#34;path&amp;#34;:&amp;#34;/spec/ports/0/nodePort&amp;#34;,&amp;#34;value&amp;#34;: 30100}]&amp;#39; kubectl patch svc spin-gate -n spinnaker --type=&amp;#39;json&amp;#39; -p &amp;#39;[{&amp;#34;op&amp;#34;:&amp;#34;replace&amp;#34;,&amp;#34;path&amp;#34;:&amp;#34;/spec/ports/0/nodePort&amp;#34;,&amp;#34;value&amp;#34;: 30200}]&amp;#39; 이제 Spinnaker로 접속하여 확인합니다.</description></item><item><title>Install in Air Gaped Environment</title><link>http://kimmj.github.io/spinnaker/installation/install-in-air-gaped-environment/</link><pubDate>Mon, 20 Jan 2020 01:16:52 +0900</pubDate><guid>http://kimmj.github.io/spinnaker/installation/install-in-air-gaped-environment/</guid><description>이번에는 인터넷이 되지 않는 환경에서 어떻게 Spinnaker를 설치하는지에 대해 알아보도록 하겠습니다.
먼저 halyard에서 언제 인터넷과 통신하는지를 대강 추려보도록 하겠습니다.
Spinnaker의 version.yaml을 불러와서 최신의 halyard 버전과 최신 Spinnaker의 버전들을 보여줍니다. gs://halconfig/version.yml 설치하고자 하는 Spinnaker의 버전을 선택하면, 그에 따른 배포에 필요한 yaml들을 불러옵니다. gs://halconfig/bom/VERSION.yml gs://halconfig/MICRO_SERVICE/TAG.yml deploy를 하기 위해 Google Cloud Repository에서 이미지를 가지고 옵니다. gcr.io/spinnaker-marketplace/SERVICE 마지막으로 dependency가 있는 몇가지 서비스를 Google Cloud Repository에서 가지고옵니다.</description></item><item><title>Kubernetes Service는 어떻게 iptables 설정이 되는가</title><link>http://kimmj.github.io/kubernetes/kubernetes-service-iptables/</link><pubDate>Wed, 10 Feb 2021 16:18:17 +0900</pubDate><guid>http://kimmj.github.io/kubernetes/kubernetes-service-iptables/</guid><description>kube-proxy 는 daemonset 으로 각각의 노드에 모두 떠있다. 역할은 kubernetes에서의 service 가 가지고 있는 Virtual IP 로 트래픽을 전달할 수 있도록 적절한 조작을 해주는 것이다. 기본적으로 3가지 모드가 있으나, 일반적으로는 iptables 모드를 많이 사용한다.
User space
iptables
Linux Kernel 에서의 netfilter 를 사용하여 kubernetes 서비스에 대한 라우팅을 설정하는 것이다. 이 모드가 default 옵션이다. 여러개의 pod 로 트래픽을 load balancing 할 때 unweighted round-robin scheduling 을 사용한다.</description></item><item><title>Kubernetes Components</title><link>http://kimmj.github.io/kubernetes/concepts/kubernetes-components/</link><pubDate>Tue, 09 Feb 2021 17:29:15 +0900</pubDate><guid>http://kimmj.github.io/kubernetes/concepts/kubernetes-components/</guid><description>각 Components 에 대해 알아보자.
Control Plane Component ETCD partition tolerance(분할 내성)보다 consistency(일관성)에 중점을 둔 db. ETCD 는 간단한 unstructured value를 저장하기에 좋다.
consistency를 중요하게 여기기 때문에 write의 순서를 엄격하게 규정하여 set value 시 atomic한 update를 제공한다.
client는 특정한 key namespace에 대해 subcription을 하여 변화를 감지할 수 있다. 따라서 어떤 component가 ETCD에 write를 할 경우 다른 component는 즉각적으로 그 변화에 대응할 수 있다.
kube-apiserver Kubernetes에서 ETCD와 통신하는 유일한 시스템이다. ETCD로의 접근 시도에 대해 필터링을 한다.</description></item><item><title>Kubernetes에서의 cpu requests, cpu limits는 어떻게 적용될까</title><link>http://kimmj.github.io/kubernetes/kubernetes-cpu-request-limit/</link><pubDate>Tue, 22 Dec 2020 02:02:49 +0900</pubDate><guid>http://kimmj.github.io/kubernetes/kubernetes-cpu-request-limit/</guid><description>Kubernetes 에서는 컨테이너 단위로 resource를 할당할 수 있다. 여기에는 memory, cpu, ephemeral-storage, hugepages 등이 포함된다. 이 중에서 cpu 의 requests, limits 가 어떤 방식으로 적용이 되는지에 대해 알아볼 것이다.
Linux Kernel 먼저 기본적으로 Kubernetes는 Linux Kernel의 cgroup을 사용하여 리소스 할당을 한다. cgroup은 control groups 의 의미를 가지며 프로세서들의 자원(cpu, memory 등)을 제한하는 기술이다.
CPU Share cpu.shares는 CPU를 다른 group에 비해 상대적으로 얼마나 사용할 수 있는지를 나타내는 값이다. 예를 들어 하나의 CPU를 가지고 있고, 두개의 group이 있다고 해보자.</description></item><item><title>Linux에서 압축파일 분할하기</title><link>http://kimmj.github.io/ubuntu/split-tgz/</link><pubDate>Sun, 06 Dec 2020 17:52:11 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/split-tgz/</guid><description>Linux 환경에서 압축파일을 분할하는 방법에 대해 알아볼 것이다.
Prerequisite tar binary installed split binary installed cat binary installed How to split 다음은 이번에 할 압축분할에 대한 간단한 flow 이다.
graph TD A[Files] --&amp;gt;|Compress with tar| B(tar output) B --&amp;gt; |Split file with split| C(splited files) C --&amp;gt; |Join splitted files with cat| D(single file) D --&amp;gt; |Express with tar| E(Files) Compress with tar 먼저 우리가 알고있는 일반적인 방법으로 압축을 하여 하나의 파일로 만든다.</description></item><item><title>Samba를 통한 디스크 공유</title><link>http://kimmj.github.io/ubuntu/samba/</link><pubDate>Sat, 28 Nov 2020 00:42:06 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/samba/</guid><description>Samba는 리눅스에 있는 폴더를 윈도우와 공유하기 위해 사용한다. 최초에 NFS로 구성했으나 NFS는 다음과 같은 문제점이 있었다.
폴더 전체를 rwx 권한을 주게 만들거나 nobody:nogroup으로 모든 권한을 폴더에 줘야 했다. perforce와 연동하려고 구성한 것이었는데 1번의 문제로 인해 자꾸 충돌이 발생했다. 이때문에 다른 대안을 찾던 중 samba를 알게 되었고, 이를 내 컴퓨터에도 적용해보았다.
Samba 구성 samba 설치 apt install samba -y samba 설정 /etc/samba/smb.conf 파일을 열어 수정한다.
[workspace] # 여기서 workspace는 접근할 때 사용되는 이름 comment = workspace path path = /path read only = no ritable = yes browseable = yes guest ok = yes available = yes public = yes valid users = root user 추가 실제 passwd에 등록된 계정으로 설정해야 한다.</description></item><item><title>CoreDNS를 통한 Dns Server 구축하기 with docker</title><link>http://kimmj.github.io/coredns/configure-dns-server/</link><pubDate>Sat, 21 Nov 2020 01:14:13 +0900</pubDate><guid>http://kimmj.github.io/coredns/configure-dns-server/</guid><description>CoreDNS는 kubernetes에서 dns resolve를 위해 사용하고 있는 오픈소스이다. 실제로 kubernetes의 kube-system 네임스페이스를 보면 coredns-xxx 파드가 떠있는 것이 보일 것이다.
사내에서 CoreDNS를 통한 DNS 서버를 구축하며 알게된 사실들, 구축 방법등을 공유한다.
CoreDNS를 시작하는 것은 정말 어렵지 않다. docker를 통해 컨테이너만 실행시켜도 우선은 CoreDNS를 맛볼 수 있다. 다만 나의 경우 docker를 그 자체로 실행시키는 것 보다 docker-compose를 통해 실행시키는 것을 더 선호하는 편이다. docker-compose의 장점이라면 복잡한 docker 명령어를 일일이 기억하고 있지 않아도 docker-compose up -d 명령어 하나로 사전에 설정된 명령을 실행시킬수 있다는 것이다.</description></item><item><title>Private Docker Registry 오픈소스: Harbor란</title><link>http://kimmj.github.io/harbor/what-is-harbor/</link><pubDate>Sun, 18 Oct 2020 16:52:12 +0900</pubDate><guid>http://kimmj.github.io/harbor/what-is-harbor/</guid><description>Harbor란 Harbor 는 올해(20년) 중순 쯤 CNCF 의 graduated된 오픈소스 프로젝트로 Docker Hub 처럼 이미지를 저장할 수 있는 저장소이다. Docker 는 이미 docker registry 라는 이름으로 개인 이미지 저장소를 컨테이너화 하였었다. Harbor 는 내부적으로 이 docker registry 를 사용하고 있으며, 여기에 RBAC, web page, image scan 같은 편리한 기능을 추가하였다. 외부 서비스를 이용하는 것이 아니라 내부에 이미지 파일을 저장하기 때문에 사내 보안 정책에도 알맞게 사용할 수 있다. 아니면 필요에 따라 S3나 Minio를 사용할 수 있을듯 하다.</description></item><item><title>CKA: Certified Kubernetes Administrator 취득 후기</title><link>http://kimmj.github.io/kubernetes/cka-epilogue/</link><pubDate>Thu, 16 Jul 2020 13:10:22 +0900</pubDate><guid>http://kimmj.github.io/kubernetes/cka-epilogue/</guid><description>작년부터 미뤄왔던 CKA: Certified Kubernetes Administrator 취득을 드디어 하게 되었습니다. 이제까지 제가 했던 공부들을 공유하며 이 시험을 보려는 사람들에게 유용한 정보를 주기 위해 이 포스트를 작성합니다.
저는 다음과 같이 CKA를 취득하였습니다.
점수: 97점 (커트라인: 74점) 유효기간: 2020.07 ~ 2023.07 (3년) CKA는 CNCF를 리딩하는 Linux Foundation에서 주관하는 시험입니다. 가격은 정가 $300으로 저렴하지는 않은 편입니다. 그러나 할인행사를 많이 하므로 급하지 않다면 시간을 가지고 천천히 결제하는게 좋습니다. 결제 후 1년까지 총 두번의 시험을 치룰 수 있습니다.</description></item><item><title>Workspace@2를 변경하기 - Workspace List 설정 변경</title><link>http://kimmj.github.io/jenkins/workspace-list/</link><pubDate>Thu, 16 Apr 2020 16:23:22 +0900</pubDate><guid>http://kimmj.github.io/jenkins/workspace-list/</guid><description>운용하는 노드에 executor가 2개 이상이라면, concurrent build 옵션을 disable했다고 하더라도 zombie process가 있을 경우 workspace@2처럼 @ 캐릭터가 들어간 workspace를 사용할 수 있다.
workspace 안에 특정한 파일을 넣고 사용하는 경우라면 @2가 생기면 안될 것이다. 그러나 이는 그렇게 좋은 방법은 아닌것 같으며 이런 경우에는 github 등에 스크립트같은 파일을 옮겨놓고 git pull이나 git 관련 플러그인을 통해 다운로드 한 뒤 사용하는 것이 더 좋은 방법인 것 같다.
하지만 나의 경우 Perforce를 사용하고 있었느데 p4 sync에서 문제가 발생했다.</description></item><item><title>[번역] 쿠버네티스에서의 Port, TargetPort, NodePort</title><link>http://kimmj.github.io/kubernetes/port-targetport-nodeport-in-kubernetes/</link><pubDate>Sun, 15 Mar 2020 23:13:37 +0900</pubDate><guid>http://kimmj.github.io/kubernetes/port-targetport-nodeport-in-kubernetes/</guid><description>원문: https://matthewpalmer.net/kubernetes-app-developer/articles/kubernetes-ports-targetport-nodeport-service.html
쿠버네티스의 port declaration 필드에는 여러가지가 있다. 각 type에 대해 빠르게 살펴보고 YAML에서 각각 어떤 의미를 가지고 있는지 알아보도록 하자.
Pod ports list pod.spec.containers[].ports로 정의된 이 배열은 container가 노출하고 있는 포트의 리스트를 나타낸다. 이 리스트를 꼭 작성해야할 필요는 없다. 리스트가 비어있다고 하더라도 container가 포트를 listening하고 있는 한 여전히 네트워크 접속이 가능하다. 이는 단순히 쿠버네티스에게 추가적인 정보를 줄 뿐이다.
List of ports to expose from the container. Exposing a port here gives the system additional information about the network connections a container uses, but is primarily informational.</description></item><item><title>http를 사용하는 docker registry를 위한 insecure registry 설정</title><link>http://kimmj.github.io/docker/insecure-registry/</link><pubDate>Sun, 15 Mar 2020 04:18:15 +0900</pubDate><guid>http://kimmj.github.io/docker/insecure-registry/</guid><description>회사같은 곳에서는 보안상의 문제 때문에 Dockerhub에다가 이미지를 올리지 못하는 경우가 많습니다. 이를 위해서 docker에서도 docker registry라는 툴을 제공하는데요, 이는 자신의 local server를 구축하고, dockerhub처럼 이미지를 올릴 수 있는 툴입니다.
이러한 docker registry는 사용자의 환경에 따라 http를 사용하는 경우가 있습니다. 이 때, docker는 default로 https 통신을 하려 하기 때문에 문제가 발생합니다. 이 경우 다음과 같이 조치를 하면 http 통신을 할 수 있습니다.
절차 insecure-registry 설정 /etc/docker/daemon.json 파일을 열어 예시처럼 작성합니다. 없을 경우 생성하면 됩니다.</description></item><item><title>Ubuntu의 Login Message 수정하기</title><link>http://kimmj.github.io/ubuntu/customize-login-message/</link><pubDate>Wed, 11 Mar 2020 14:20:42 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/customize-login-message/</guid><description>TLDR Expand me... This package seeks to make the /etc/motd (Message of the Day) more dynamic and valuable, by providing a simple, clean framework for defining scripts whose output will regularly be written to /etc/motd.
Ubuntu에서는 /etc/update-motd.d 안에 있는 파일들을 확인하여 console, ssh 등 어떤 방법으로든 로그인했을 때 메시지를 띄워줍니다. 여기서 파일들을 사전순으로 로딩하게 됩니다.
따라서 해당 폴더에 적절한 파일들을 생성하게 된다면 로그인 시 출력되는 메시지를 조작할 수 있습니다.</description></item><item><title>background image 어둡게 하기</title><link>http://kimmj.github.io/css/background-img-darken/</link><pubDate>Tue, 10 Mar 2020 23:40:25 +0900</pubDate><guid>http://kimmj.github.io/css/background-img-darken/</guid><description>배경 이미지를 삽입했는데 사진이 너무 밝아 어둡게 필터처리를 넣고 싶은 경우가 있을 수 있습니다. 저의 경우 logo에 제 깃허브 프로필사진을 빼고 노을진 풍경을 넣었는데 사진이 너무 밝아 부자연스러운 느낌이 들었습니다.
이 때 검색 후 다음과 같이 조치를 하여 어두워지는 효과를 줄 수 있었습니다.
#sidebar #header-wrapper { background-image: linear-gradient( rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3) ),url(../images/sunset_on_ibiza.jpg); } linear-gradient 속성은 선형으로 gradient를 적용하는 속성인데 이를 활용하여 검정색 필터를 넣었습니다. 필수 파라미터로 두개의 색깔이 필요하고, 이를 각각 검정색(rgb(0, 0, 0))에 투명도를 0.</description></item><item><title>Hugo에 Google Analytics 적용하기</title><link>http://kimmj.github.io/hugo/google-analytics/</link><pubDate>Mon, 09 Mar 2020 23:19:18 +0900</pubDate><guid>http://kimmj.github.io/hugo/google-analytics/</guid><description>google analytics는 내 블로그를 사용하는 사람들이 얼마나 많은지, 어떤 정보를 보는지 확인할 수 있는 서비스입니다. 무료로 사용할 수 있고, 사용 방법도 어렵지 않기 때문에 search console과 더불어 사용하면 좋은 서비스로 보입니다.
그래서 저도 제 블로그에 google analytics를 설정할 수 있는지 찾아보던 중 다음과 같은 글을 확인하고, 이를 통해 설정할 수 있었습니다.
https://discourse.gohugo.io/t/implementing-google-analytics-in-hugo/2671/2
적용 방법 config.toml의 수정 hugo에서는 config 파일을 사용하여 사용자의 설정정보를 보관합니다. 저는 config.toml을 사용하고 있었는데 여기에다가 다음과 같이 추가하면 됩니다.</description></item><item><title>git-secret을 통한 github 파일 암호화</title><link>http://kimmj.github.io/git/git-secret/</link><pubDate>Sat, 07 Mar 2020 23:39:23 +0900</pubDate><guid>http://kimmj.github.io/git/git-secret/</guid><description>git을 사용하다 보면 password나 credential같은 정보가 git에 올라가는 경우가 종종 있습니다. aws같은 cloud provider의 crediential을 git에 생각없이 올리고, 이를 다른 해커가 크롤링을 통해 얻어 비트코인을 채굴하는 사례도 있었습니다.
이처럼 보안이 필요한 파일을 git에 올릴 때, 암호화를 하여 업로드하는 방법이 있습니다.
https://github.com/sobolevn/git-secret
git-secret git-secret은 파일에 대한 암화를 지원하기 위해 사용되는 프로그램입니다.
git-secret add 명령어를 통해 파일을 암호화하고, git-secret reveal을 통해 복호화합니다. 이 때 gpg를 이용하게 됩니다.
Install 사용자 환경에 따라 brew, apt, yum을 통해 설치할 수 있습니다.</description></item><item><title>Harbor 설치</title><link>http://kimmj.github.io/harbor/install/</link><pubDate>Tue, 03 Mar 2020 10:07:50 +0900</pubDate><guid>http://kimmj.github.io/harbor/install/</guid><description>docker-compose 설치 $ sudo curl -L &amp;#34;https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)&amp;#34; -o /usr/local/bin/docker-compose $ sudo chmod +x /usr/local/bin/docker-compose # 설치 후 docker-compose 명령어가 실패한다면, symbolic link를 직접 걸어주도록 합니다. $ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose $ docker-compose --version docker-compose version 1.24.1, build 1110ad01 harbor installer 다운로드 공식 Github에서 원하는 인스톨러를 다운로드 받습니다. 저는 online installer를 사용할 예정입니다.
다운로드가 완료되었으면 압축을 해제합니다.
$ tar xvf harbor-*.tgz harbor/prepare harbor/LICENSE harbor/install.sh harbor/common.sh harbor/harbor.yml harbor.yml 설정 vi로 harbor/harbor.</description></item><item><title>reboot 후에 tmux를 실행시켜 원하는 작업을 하기</title><link>http://kimmj.github.io/ubuntu/start-tmux-after-reboot/</link><pubDate>Sat, 29 Feb 2020 14:00:40 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/start-tmux-after-reboot/</guid><description>tmux는 terminal을 한 창에 여러개 띄울 때 사용하는 프로그램입니다.
이 프로그램의 특징은 detach 모드로 들어가면, 어디서든 terminal에 접속하여 해당 session에 접속했을 때, 그 화면 그대로를 가져올 수 있다는 것입니다.
즉, 원격 접속을 통해 서버에 접속했을 때 작업을 돌려놓고 detach모드로 들어가면 나의 session을 꺼도 실제 서버에서는 해당 작업이 계속해서 돌아가고 있다는 것입니다. 퇴근하기 전 시간이 오래걸리는 작업을 돌려놓고 가야할 때 유용하게 사용할 수 있습니다.
저의 경우는 제 로컬 컴퓨터에서 hugo를 통해 사이트를 생성하여 블로그를 편집할 때마다 즉시 그 결과를 보고 있습니다.</description></item><item><title>Docker를 sudo없이 실행하기</title><link>http://kimmj.github.io/docker/use-docker-without-sudo/</link><pubDate>Sat, 29 Feb 2020 02:51:19 +0900</pubDate><guid>http://kimmj.github.io/docker/use-docker-without-sudo/</guid><description>docker 명령어는 docker group으로 실행됩니다. 그러나 저희가 기존에 사용하던 일반 user는 해당 group에 속하지 않기 때문에 docker 명령어를 쳤을 때 permission에 관한 에러가 발생하게 됩니다.
이 때 다음과 같이 조치를 하면 sudo 없이 user가 docker 명령어를 사용할 수 있게 됩니다.
sudo usermod -aG docker $USER session을 다시 열고 docker ps 명령어를 입력하여 에러가 발생하는지 확인합니다.
$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES</description></item><item><title>oh-my-zsh에서 home key와 end key가 안될 때 해결방법</title><link>http://kimmj.github.io/ubuntu/oh-my-zsh-home-end-key/</link><pubDate>Sat, 29 Feb 2020 02:27:25 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/oh-my-zsh-home-end-key/</guid><description>oh-my-zsh을 설치하고 원격접속이나 로컬환경에서 터미널에 접속했을 때 home key와 end key가 먹히지 않는 경우가 있습니다.
이런 경우에 사용하는 terminal에서 home key와 end key를 눌러 실제 어떤 값이 전달되는지 확인한 후, 이를 beginning-of-line, end-of-line으로 설정하면 해결할 수 있습니다.
해결법 home key가 되지 않는 terminal에 접속합니다. Control+V를 누릅니다. 문제가 되는 home key를 누릅니다. terminal에 뜬 문자를 기록합니다. ~/.zshrc에 다음과 같이 추가합니다. 여기서 case에 관한 부분은 상황에 따라 넣지 않거나 변경해야 합니다. case $TERM in (xterm*) bindkey &amp;#39;^[[H&amp;#39; beginning-of-line bindkey &amp;#39;^[[F&amp;#39; end-of-line esac source ~/.</description></item><item><title>Ubuntu에서 Base64로 인코딩, 디코딩하기</title><link>http://kimmj.github.io/ubuntu/base64-encode-decode/</link><pubDate>Thu, 27 Feb 2020 20:44:42 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/base64-encode-decode/</guid><description>Encode echo로 입력하기 $ echo &amp;#34;password&amp;#34; | base64 cGFzc3dvcmQK Control+D를 누를때까지 입력하기 $ base64 admin password ^D # Control+D # result YWRtaW4KcGFzc3dvcmQK Decode echo로 입력하기 $ echo &amp;#34;cGFzc3dvcmQK&amp;#34; | base64 --decode password Control+D를 누를때까지 입력하기 $ base64 --decode YWRtaW4KcGFzc3dvcmQK ^D # Control+D # result admin password</description></item><item><title>Editor(vi)가 없을 때 파일 수정하기</title><link>http://kimmj.github.io/ubuntu/file-edit-without-editor/</link><pubDate>Wed, 26 Feb 2020 17:59:29 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/file-edit-without-editor/</guid><description>echo로 파일 내용을 입력하는 방법 &amp;gt;로 파일 덮어쓰기 $ cat file asdfasdfasdf $ echo &amp;#34;asdf&amp;#34; &amp;gt; file $ cat file asdf &amp;gt;&amp;gt;로 파일에 이어쓰기 $ cat file asdf $ echo &amp;#34;asdf&amp;#34; &amp;gt;&amp;gt; file $ cat file asdf asdf cat으로 파일 입력하는 방법 &amp;gt;로 파일 덮어쓰기 $ cat file asdf $ cat &amp;gt; file aaaa bbbb ^D # Command+D $ cat file aaaa bbbb &amp;gt;&amp;gt;로 파일에 이어쓰기 $ cat file asdf $ cat &amp;gt;&amp;gt; file aaaa bbbb ^D # Command+D $ cat file asdf aaaa bbbb &amp;laquo;EOF로 EOF을 입력하면 입력 완료하기 $ cat file asdf $ cat &amp;lt;&amp;lt;EOF &amp;gt; file aaaa bbbb EOF $ cat file asdf aaaa bbbb</description></item><item><title>Stern을 이용하여 여러 pod의 log를 한번에 확인하기</title><link>http://kimmj.github.io/kubernetes/stern/</link><pubDate>Mon, 24 Feb 2020 23:28:01 +0900</pubDate><guid>http://kimmj.github.io/kubernetes/stern/</guid><description>Kubernetes에서의 trouble shooting kubernetes 환경에서 어떤 문제가 발생하면 다음과 같은 flow로 확인을 해보면 됩니다.
kubectl get pods -o yaml로 yaml을 확인하기 kubectl describe pods로 pod에 대한 설명 확인하기 kubectl describe deployments(statefulset, daemonset)으로 확인하기 kubectl logs로 로그 확인하기 보통 kubernetes 리소스의 부족과 같은 kubernetes단의 문제는 1~3을 확인하면 전부 문제점을 찾을 수 있습니다. 그러나 어플리케이션의 직접적인 원인을 알아보기 위해서는 log를 확인해야 합니다.
하지만 kubectl의 logs에는 한가지 한계점이 있는데, 바로 단일 container에 대해서만 log 확인이 가능하다는 점입니다.</description></item><item><title>Gitignore 설정</title><link>http://kimmj.github.io/git/gitignore/</link><pubDate>Mon, 24 Feb 2020 14:28:13 +0900</pubDate><guid>http://kimmj.github.io/git/gitignore/</guid><description>참조: https://git-scm.com/docs/gitignore
gitignore은 git에서 어떤 파일을 무시할지 설정하는 파일입니다. 이미 tracked된 것들에는 영향을 주지 않습니다.
gitignore 참조 순서 syntax blank line 파일과 매칭되지 않습니다. 따라서 가독성을 위해 사용할 수 있습니다.
# #은 comment로 처리됩니다.
Traling space \로 감싸졌다고 하더라도 무시됩니다.
! !는 not과 같습니다. 파일 이름 맨 앞에 !가 있고, 이를 ignore할 때 사용하려면 \를 통해 escape 해줘야 합니다.
/ /는 디렉토리를 구분합니다. 처음, 중간, 끝 어느 위치에도 올 수 있습니다.</description></item><item><title>열려있는 포트 확인하기</title><link>http://kimmj.github.io/ubuntu/check-listen-port/</link><pubDate>Mon, 24 Feb 2020 13:38:04 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/check-listen-port/</guid><description>열려있는 포트 확인하기 # 방법 1 lsof -i -nP | grep LISTEN | awk &amp;#39;{print $(NF-1)&amp;#34; &amp;#34; $1}&amp;#39; | sort -u # 방법 2 netstat -tnlp 열려있는 포트 확인하기 + 관련된 프로세스 이름 확인하기 netstat -tnlp | grep -v 127.0.0.1 | sed &amp;#39;s/:::/0 /g&amp;#39; | sed &amp;#39;s/[:\/]/ /g&amp;#39; | awk &amp;#39;{print $5&amp;#34;\t&amp;#34;$10}&amp;#39; | sort -ug</description></item><item><title>pipe를 사용한 명령어를 watch로 확인하기</title><link>http://kimmj.github.io/ubuntu/using-watch-with-pipes/</link><pubDate>Sun, 23 Feb 2020 16:07:38 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/using-watch-with-pipes/</guid><description>pipe(|)는 grep과 다른 기타 명령어들과 함께 사용하면 좀 더 다양한 작업을 할 수 있습니다.
watch는 특정 명령어를 주기적으로 입력하여 결과 메시지를 확인합니다. 즉, 무엇인가를 모니터링할 때 주로 사용하곤 합니다.
바로 본론으로 들어가서 pipe를 사용한 명령어를 watch로 확인하는 방법은 다음과 같습니다.
watch &amp;#39;&amp;lt;command&amp;gt;&amp;#39; 위와같이 quote로 감싸주세요.
ls -al을 가지고 확인해 보도록 하겠습니다.
$ ls -al | grep config -rw-rw-r-- 1 wanderlust wanderlust 2.9K 1월 21 23:40 config.toml $ watch ls -al | grep config # quote를 사용하지 않은 것 ^C # 결과 출력되지 않음 $ watch &amp;#34;ls -al | grep config&amp;#34; Every 2.</description></item><item><title>watch를 사용할 때 alias 이용하기</title><link>http://kimmj.github.io/ubuntu/use-alias-in-watch/</link><pubDate>Sat, 22 Feb 2020 23:33:02 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/use-alias-in-watch/</guid><description>watch는 정해진 시간동안 뒤에 적은 명령어를 실행해주는 프로그램입니다. 가령 kubernetes를 다룰 때 watch kubectl get pods -n kube-system을 통해 kube-system 네임스페이스에 있는 파드들을 지속적으로 모니터링 할 수 있습니다.
그러나 watch는 alias된 명령어를 인식하지 못합니다.
$ ll total 44K drwxrwxr-x 2 wanderlust wanderlust 4.0K 1월 7 20:38 archetypes -rw-rw-r-- 1 wanderlust wanderlust 2.9K 1월 21 23:40 config.toml drwxrwxr-x 16 wanderlust wanderlust 4.0K 2월 22 23:08 content $ watch ll Every 2.0s: ll sh: 1: ll: not found 이 때 해결할 수 있는 가장 편한 방법은 watch 자체를 alias 시켜버리는 것입니다.</description></item><item><title>[번역]Python을 통해 이쁜 CLI 만들기</title><link>http://kimmj.github.io/python/python-beautiful-cli/</link><pubDate>Sat, 22 Feb 2020 23:08:39 +0900</pubDate><guid>http://kimmj.github.io/python/python-beautiful-cli/</guid><description>링크 : https://codeburst.io/building-beautiful-command-line-interfaces-with-python-26c7e1bb54df
command line application을 만드는 것을 다루기 전에 빠르게 Command Line에 대해서 알아보자.
command line 프로그램은 컴퓨터 프로그램이 생성되었을 때부터 우리와 함께 해왔고, 명령어들로 구성되어있다. commnad line 프로그램은 command line에서 또는 shell에서 동작하는 프로그램이다.
command line interface는 user interface이지만 마우스를 사용하는 것이 아닌 terminal, shell, console에서 명령어를 입력하여 사용하는 것이다. console은 이미지나 GUI가 하나도 없이 전체 모니터 스크린이 텍스트로만 이루어진 것을 의미한다.
위키피디아에 의하면
CLI는 주로 1960년대 중만에 컴퓨터 terminal에서의 대부분의 컴퓨터 시스템과의 상호작용을 의미하고 1970년대와 1980년대를 거쳐 OpenVMS, MS-DOS를 포함한 개인용 컴퓨터와 Unix system, CP/M과 Apple DOS에서 사용되어 왔다.</description></item><item><title>[docker-compose] container에서 다른 container로 접속하기</title><link>http://kimmj.github.io/docker/connect-container-to-container/</link><pubDate>Fri, 21 Feb 2020 18:58:15 +0900</pubDate><guid>http://kimmj.github.io/docker/connect-container-to-container/</guid><description>배경 docker-compose에서는 network bridge를 설정합니다. 이 bridge로 내부 통신을 하게 되죠. 여기서 port-forward를 통해 외부로 서비스를 expose하게 되면 host의 IP와 port의 조합으로 접속할 수 있습니다.
그런데 저는 네트워크 설정의 문제인지, 하나의 container에서 host IP로 접속이 불가능했습니다. 그러면서도 저는 어떻게든 다른 docker-compose의 서비스로 네트워킹이 됐어야 했습니다. 정확히 말하자면 harbor라는 서비스(docker registry)에서 jenkins로 webhook을 날려야 하는 상황이었죠.
먼저 시도했던 것은 jenkins의 ip를 docker inspect jenkins_jenkins_1을 통해 알아내고, 이를 통해 webhook을 전송하는 것이었습니다. 그러나 실패했죠.</description></item><item><title>password 없이 ssh 접속하기</title><link>http://kimmj.github.io/ubuntu/ssh-without-password/</link><pubDate>Sat, 15 Feb 2020 15:48:57 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/ssh-without-password/</guid><description>자주 접속하는 서버에 패스워드를 항상 입력하는 것은 귀찮은 일이 될 것입니다.
여기에서는 ssh key를 생성하고, 이를 이용하여 인증을 해 password를 입력하지 않는 방법을 알아볼 것입니다.
ssh-keygen을 통한 ssh key 생성 ssh 접속을 할 때 password를 입력했던 것처럼, 항상 ssh 접속을 위해서는 인증을 위한 key가 필요합니다.
인증에 사용할 키를 ssh-keygen으로 생성하는 방법은 다음과 같습니다.
ssh-keygen -t rsa -b 4096 -t는 rsa 알고리즘을 통해 key를 생성하겠다는 의미이며, -b는 key의 사이즈를 정해주는 것입니다.</description></item><item><title>SSH Tunneling 사용법</title><link>http://kimmj.github.io/ubuntu/ssh-tunneling/</link><pubDate>Thu, 13 Feb 2020 21:16:02 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/ssh-tunneling/</guid><description>-D 옵션으로 socks proxy 사용하기 A라는 서버에서 B라는 서버에 있는 서비스를 보려고 합니다. 이 때, 해당 웹 어플리케이션은 B에서만 연결된 특정 IP로 통신을 하고 있고, 이 때문에 A에서 어플케이션이 제대로 동작하지 않는 상황입니다.
이 때 사용할 수 있는 것이 -D 옵션입니다.
예시
ssh -D 12345 user@server.com 해당 세션이 꺼져있지 않은 상태에서 A 서버에서 웹 브라우저가 localhost:12345를 프록시로 사용하도록 하면 해당 웹 어플리케이션이 제대로 동작합니다.
만약 windows라면 다음과 같이 진행하면 socks proxy를 사용하도록 할 수 있습니다.</description></item><item><title>Gateway를 이용하여 SSH 접속하기</title><link>http://kimmj.github.io/ubuntu/ssh-with-jump/</link><pubDate>Wed, 12 Feb 2020 22:08:16 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/ssh-with-jump/</guid><description>ssh cli 이용하는 방법 -J 옵션을 이용한다.
ssh user@server -J user2@server2 두개 이상의 경우 ,로 구분한다.
예: user2@server2로 접속 후 user3@server3로 접속한 뒤 user@server로 접속해야 할 경우
ssh user@server -J user2@server2,user3@server3 이 상황에서 ssh-copy-id를 이용해 패스워드를 입력하지 않고 이동하려면
localuser@localhost $ ssh-copy-id user2@server2 localuser@localhost $ ssh user2@server2 user2@server2 $ ssh-copy-id user3@server3 user2@server2 $ ssh user3@server3 user3@server3 $ ssh-copy-id user@server 이후 ssh를 통해 진입하면 패스워드 없이 접속 가능.
만약 port가 필요한 경우 server:port 형태로 입력</description></item><item><title>[번역] What Is Infrastructure as a Code? How It Works, Best Practices, Tutorials</title><link>http://kimmj.github.io/iac/translate-what-is-infrastructure-as-a-code/</link><pubDate>Sun, 09 Feb 2020 20:06:17 +0900</pubDate><guid>http://kimmj.github.io/iac/translate-what-is-infrastructure-as-a-code/</guid><description>link: https://stackify.com/what-is-infrastructure-as-code-how-it-works-best-practices-tutorials/
과거에 IT infrastructure를 관리하는 것은 힘든 일이었다. 시스템 관리자는 수동으로 관리하고 어플리케이션을 구동시키기 위해 모든 하드웨어와 소프트웨어를 설정해야 했다.
하지만 최근 몇년간 급격하게 상황들이 바뀌었다. cloud computing같은 트렌드가 디자인, 개발, IT infrastructure의 유지를 하는 방법을 혁명화하고 발전시켰다.
이러한 트렌드의 핵심 요소는 infrastructure as code이다. 여기에 대해 이야기 해보도록 하겠다.
Defining Infrastructure as Code infrastructure를 코드로 정의하는 것부터 시작해보도록 하자. 이것이 무엇을 의미하는지, 어떤 문제들을 해결하는지 배우게 될 것이다.</description></item><item><title>Deploy Strategy</title><link>http://kimmj.github.io/cicd/deploy-strategy/</link><pubDate>Mon, 03 Feb 2020 14:09:25 +0900</pubDate><guid>http://kimmj.github.io/cicd/deploy-strategy/</guid><description>Deploy Strategy 실제 시스템을 운용할 때 중요하게 여겨지는 것 중 하나가 downtime을 없애는 것이다. 새로운 업데이트가 있을 때마다 해당 인스턴스가 동작하지 않는다면, 자주 업데이트 하는 것이 어려워질 수 있습니다. 따라서 deploy strategy를 가지고 어떻게 downtime을 줄이는지 알아보도록 하겠습니다.
Canary canary deploy는 트래픽 비율을 바꾸어가며 배포하는 전략입니다. 이해하기 편하도록 Kubernetes 환경이라고 생각해 보도록 하겠습니다. (또는 LoadBalancer가 있어서 부하를 분산하고 있다고 생각하면 좋을 것 같습니다.) 이 때 업데이트된 버전을 따로 올리고 트래픽을 old:new = 100:0으로 줍니다.</description></item><item><title>Pods</title><link>http://kimmj.github.io/kubernetes/concepts/pods/</link><pubDate>Mon, 03 Feb 2020 14:03:50 +0900</pubDate><guid>http://kimmj.github.io/kubernetes/concepts/pods/</guid><description>Pod Overview Pod의 이해 Pod는 Kubernetes에서 가장 작은 배포 오브젝트이며 쿠버네티스에서 관리하는 최소 관리 단위입니다. Pod는 cluster 안에서 실행중인 어떤 프로세스를 의미합니다. application container, 스토리지 리소스, 유일한 network ip, container가 어떻게 실행할지를 캡슐화한 것입니다.
각각의 Pod는 주어진 application에서 단일 인스턴스를 수행합니다. 즉, 한가지 역할을 맡고 있다고 생각하시면 됩니다.. 따라서 application을 수직확장하고 싶다면 각 인스턴스에 대해 여러 Pod를 생성하면 된다. 그러면 동일한 역할을 하는 Pod가 늘어나니, 병렬적으로 처리가 가능할 것입니다.
Pod는 서비스 중에서 서로 연관성이 높은 프로세스를 지원하기 위해 디자인되었습니다.</description></item><item><title>Greater Than Sign</title><link>http://kimmj.github.io/css/greater-than-sign/</link><pubDate>Sat, 01 Feb 2020 19:56:45 +0900</pubDate><guid>http://kimmj.github.io/css/greater-than-sign/</guid><description>&amp;gt;의 의미 &amp;gt;는 child-combinator 입니다.
다음의 예시를 통해 정확히 어떤 역할을 하는지 알아보도록 하겠습니다.
&amp;lt;div&amp;gt; &amp;lt;p class=&amp;#34;some_class&amp;#34;&amp;gt;Some text here&amp;lt;/p&amp;gt; &amp;lt;!-- Selected [1] --&amp;gt; &amp;lt;blockquote&amp;gt; &amp;lt;p class=&amp;#34;some_class&amp;#34;&amp;gt;More text here&amp;lt;/p&amp;gt; &amp;lt;!-- Not selected [2] --&amp;gt; &amp;lt;/blockquote&amp;gt; &amp;lt;/div&amp;gt; 위와 같은 예시에서 div &amp;gt; p.some_class는 div 바로 밑에 있는 p.some_class만을 선택합니다. &amp;lt;blockquote&amp;gt;로 감싸진 p.some_class는 선택되지 않습니다.
이와는 다르게 space만 사용하는 descendant combinator는 두개의 p.some_class 모두를 선택합니다.</description></item><item><title>Hugo에 Comment 추가하기 (Utterance)</title><link>http://kimmj.github.io/hugo/insert-comment/</link><pubDate>Fri, 24 Jan 2020 20:56:47 +0900</pubDate><guid>http://kimmj.github.io/hugo/insert-comment/</guid><description>댓글 서비스 선택 블로그를 운영하는데 관심을 가지기 시작하면서, 기본적으로 jekyll이나 hugo에는 댓글 기능이 없다는 것을 알게 되었습니다. static site를 만드는데 사실 댓글을 지원한다는게 이상한 상황이긴 하지요. 그래도 서드파티의 지원을 받으면 댓글 기능이 가능해집니다. 여러 블로그들을 탐방하며 git page 기능을 사용하는 블로그들에도 댓글이 있는것을 항상 봐왔으니까요.
따라서 댓글을 어떻게 사용하는지 검색해보게 되었습니다. 대표적인 것이 Disqus 입니다. 실제로 많은 사이트들이 Disqus를 기반으로 댓글 기능을 사용합니다.
저는 이 hugo 기반 블로그를 만드는 데 큰 도움을 준 https://ryan-han.</description></item><item><title>Tmux</title><link>http://kimmj.github.io/ubuntu/tools/tmux/</link><pubDate>Thu, 23 Jan 2020 21:04:29 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/tools/tmux/</guid><description>tmux란? tmux는 하나의 화면에서 여러개의 터미널을 키고싶을 때 사용하는 프로그램으로, ubuntu를 설치하면 기본적으로 설치되는 프로그램입니다.
다음과 같은 구조를 가집니다.
tmux ├── session │ ├── windows │ │ ├── pane │ │ └── pane │ └── windows │ ├── pane │ └── pane └── session ├── windows │ ├── pane │ └── pane └── windows ├── pane └── pane session 사용법 먼저 가장 큰 단위인 session을 다루는 방법부터 시작해보도록 하겠습니다.
session 생성 tmux 위처럼 tmux를 생성할 수 있습니다.</description></item><item><title>Federation</title><link>http://kimmj.github.io/prometheus/federation/</link><pubDate>Tue, 21 Jan 2020 23:34:44 +0900</pubDate><guid>http://kimmj.github.io/prometheus/federation/</guid><description>What is Federation 영어 의미 그대로는 &amp;ldquo;연합&amp;quot;이라는 뜻입니다. 즉, Prometheus의 Federation은 여러개의 Prometheus에서 Metric을 가져와 계층구조를 만드는 것을 의미합니다.
위의 그림에서 너무나도 잘 표현이 되어 있습니다. 그림에서 보시면 상위에 있는 Prometheus에서 하위의 Dev, Staging, Production쪽으로 화살표가 간 것을 볼 수 있습니다. 이는 아래에 있는 Prometheus가 http(s)://&amp;lt;url&amp;gt;/federation으로 보여주는 Metric들을 위쪽에 있는 Prometheus에서 scrape하기 때문입니다.
저의 상황을 설명해드리고 지나가도록 하겠습니다. 저는 Kubernetes Cluster가 Dev(Canary), Staging, Production과 비슷하게 3개 있었습니다. 여기서 Spinnaker를 통해 Dev에 새로운 이미지들을 배포할 것이고, 이에 대한 Metric을 Canary Analysis를 통해 분석하여 Dev로 배포된 이미지가 이전 Staging의 이미지와 어떻게 다른지 등을 점수화하여 Staging 서버에 배포를 할지 말지 결정하도록 해야하는 상황이었습니다.</description></item><item><title>Canary Analysis</title><link>http://kimmj.github.io/spinnaker/canaryanalysis/canary-analysis/</link><pubDate>Tue, 21 Jan 2020 01:08:00 +0900</pubDate><guid>http://kimmj.github.io/spinnaker/canaryanalysis/canary-analysis/</guid><description>Spinnaker Canary Analysis Spinnaker에는 Canary Analysis라는 자동 분석 도구가 있습니다. Kayenta라는 micro service를 사용하는데, 이를 통해 자동으로 canary deploy가 괜찮은 버전인지를 확인해 줍니다.
그러나 이 툴은 Spinnaker에서 사용하기에 여간 어려운 것이 아닙니다. 제일 먼저 봉착하는 난관은 바로 &amp;ldquo;어떻게 Canary Analysis를 활성화 하는가?&amp;ldquo;입니다.
이곳에 방법이 나와있지만, 사실 저도 엄청 많이 헤멨습니다. 저는 bare-metal 환경에서 Kubernetes cluster를 구축하였었고, aws나 azure, gcp는 사용하지 못하는 상황었습니다. (물론 지금도 집에서 VM으로 로컬에 구성하였지만, cloud platform은 언제나 과금때문에 꺼려지게 됩니다.</description></item><item><title>Hostname 변경하기</title><link>http://kimmj.github.io/ubuntu/change-hostname/</link><pubDate>Tue, 14 Jan 2020 01:00:02 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/change-hostname/</guid><description>hostname을 바꾸는 일은 흔치 않지만 최초 셋업할 때 많이 사용하곤 합니다.
# hostnamectl set-hostname &amp;lt;host name&amp;gt; hostnamectl set-hostname wonderland 변경 후 터미널을 끄고 재접속을 하면 변경된 사항을 볼 수 있습니다.
hostname</description></item><item><title>Font Change</title><link>http://kimmj.github.io/hugo/ibiza/font-change/</link><pubDate>Sun, 12 Jan 2020 16:28:31 +0900</pubDate><guid>http://kimmj.github.io/hugo/ibiza/font-change/</guid><description>Ibiza 프로젝트를 진행하는데 폰트가 마음에 들지 않았습니다. 따라서 저는 폰트를 변경하기로 마음먹었습니다.
먼저, 폰트 설정을 어디서 하는지 알아낼 필요가 있었습니다.
find . | grep font 결과를 보니, theme 폴더 안에 제가 사용하는 hugo-theme-learn 테마에서 static/fonts/ 폴더에 폰트들을 저장해두고 있었습니다. 그렇다면 어느 파일에서 어떤 폰트를 사용한다고 설정할까요?
hugo-theme-learn폴더로 이동하여 어디에 사용되는지 확인해보았습니다.
grep -ri &amp;#34;font&amp;#34; 결과가 길게 나오는데요, 여기서 static/css/theme.css 안에 폰트에 대한 설정을 한 것이 보였습니다. 그 파일을 보니, @font-face라는 설정이 보이네요.</description></item><item><title>Netplan으로 static IP 할당받기</title><link>http://kimmj.github.io/ubuntu/network/netplan/</link><pubDate>Sat, 11 Jan 2020 01:12:57 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/network/netplan/</guid><description>유선 static IP 할당 다음과 같이 static-IP-netplan.yaml을 작성합니다.
network: version: 2 ethernets: enp3s0: dhcp4: no dhcp6: no addresses: [ 192.168.1.26/24 ] gateway4: 192.168.1.1 nameservers: addresses: [ 8.8.8.8, 8.8.4.4 ] 하나씩 살펴보도록 하겠습니다.
ethernetes: 유선랜 설정입니다. enp3s0 설정을 사용할 랜카드입니다. dhcp4, dhcp6: dynamic으로 IP를 할당받는 dhcp를 disable한 것입니다. addresses: 사용할 IP 및 CIDR입니다. gateway4: IP가 사용하는 gateway입니다. nameservers: dns 주소입니다. 8.8.8.8과 8.8.4.4를 사용합니다. WIFI static IP 할당 wifis: wlp2s0: dhcp4: no dhcp6: no addresses: [ 192.</description></item><item><title>HUGO로 HTML이 되지 않을 때 가능하게 하는 방법</title><link>http://kimmj.github.io/hugo/hugo-with-html/</link><pubDate>Fri, 10 Jan 2020 02:22:34 +0900</pubDate><guid>http://kimmj.github.io/hugo/hugo-with-html/</guid><description>Hugo는 markdown을 기본적으로 사용하지만 html을 이용해서 좀 더 다양하게 커스터마이징이 가능한 장점도 가지고 있습니다.
하지만 저는 처음에 html 코드를 사용하게 되면 &amp;lt;!-- raw HTML omitted --&amp;gt;와 같은 줄로 대치가 되곤 했습니다. 구글링 결과 이는 Hugo의 버전이 0.60.0으로 되면서부터 기본적으로 disable 시켰기 때문입니다.
따라서 다음과 같이 조치를 하면 간단하게 해결이 가능합니다.
[markup.goldmark.renderer] unsafe= true 위와 같은 설정을 config.toml에 추가하기만 하면 됩니다. 추가를 한 뒤 다시 확인해보면 정상적으로 html 코드가 적용된 모습을 볼 수 있습니다.</description></item><item><title>Pipeline Expressions</title><link>http://kimmj.github.io/spinnaker/tips/pipeline-expressions/</link><pubDate>Fri, 10 Jan 2020 01:33:32 +0900</pubDate><guid>http://kimmj.github.io/spinnaker/tips/pipeline-expressions/</guid><description>Spinnaker는 배포를 자동화할 때 사용합니다. 그렇기 때문에 자동화를 위해선 다른 곳에서 사용된 값들을 가지고 와야할 필요성이 생기기도 합니다.
이 문서에서는 그럴 때 사용할 수 있는 pipeline function에 대해 알아보도록 하겠습니다.
pipeline functions pipeline에서 다른 pipeline의 값들 불러오기 Note: Pipeline expression syntax is based on Spring Expression Language (SpEL).
위의 Note에도 적었듯이, Spinnaker는 SpEL을 기반으로 Expressions를 사용합니다. SpEL에 대해 이미 잘 알고있다면 너무나도 좋겠지만, 저는 익숙하지가 않았기 때문에 많은 시행착오를 거쳐서 습득을 하게 되었습니다.</description></item><item><title>Create Vm With Ansible Libvirt</title><link>http://kimmj.github.io/ansible/create-vm-with-ansible-libvirt/</link><pubDate>Wed, 08 Jan 2020 01:52:47 +0900</pubDate><guid>http://kimmj.github.io/ansible/create-vm-with-ansible-libvirt/</guid><description>Ansible은 어떠한 프로세스를 자동화 할 때 사용할 수 있는 툴입니다. 그리고 libvirt는 linux 환경에서 qemu를 이용하여 VM을 생성할 때 사용하는 python 모듈입니다.
이 두가지를 합하여 Ansible을 통해 VM을 생성하는 방법에 대해 알아보도록 하겠습니다.
ansible-role-libvirt-vm 참조 Github : https://github.com/stackhpc/ansible-role-libvirt-vm
위의 Github 프로젝트는 libvirt를 ansible에서 사용할 수 있도록 만든 오픈소스입니다. 이를 이용하여 ansible-playbook을 통해 VM을 생성해 볼 것입니다.
이를 로컬에 clone 합니다.
git clone https://github.com/stackhpc/ansible-role-libvirt-vm 테스트 환경 저는 Ubuntu 18.04.3 Desktop을 사용하고 있습니다.</description></item><item><title>추가 입력절차(prompt) 없이 Ubuntu 설치하는 이미지 만들기</title><link>http://kimmj.github.io/ubuntu/unattended-ubuntu/</link><pubDate>Wed, 08 Jan 2020 01:52:32 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/unattended-ubuntu/</guid><description>어디에 좋을까 Ubuntu Server를 설치하기 위해서는 많은 추가 입력이 있어야 합니다. 사용자가 어떻게 설치하기를 원하는지 모르기 때문에, 또 다양한 옵션을 사용자가 선택하기 위해서는 어찌보면 당연한 것이겠지요. 하지만 만약 똑같은 설정을 사용할 것인데, 여러대의 서버에 OS를 설치하는 상황이라고 생각해보면 정말 암울합니다. 온전히 시간을 OS 설치에만 투자하자니 이건 간단한 업무로 인해 다른 업무를 보지 못하게 됩니다. 또 다른 업무와 동시에 하자니 다음 입력창이 뜰 때인지 한번씩 확인해 주어야 합니다.
따라서 어차피 같은 설정을 한다면, 이러한 설정을 미리 해 놓는 방법이 Ubuntu iso 파일 내부에 있을 것이라고 추측했습니다.</description></item><item><title>Ubuntu 설치 시 Boot Parameter를 수정하기</title><link>http://kimmj.github.io/ubuntu/how-to-edit-boot-parameter-during-install/</link><pubDate>Wed, 08 Jan 2020 01:52:12 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/how-to-edit-boot-parameter-during-install/</guid><description>Ubuntu 설치할 때 boot parameter가 필요한 상황이 간혹 발생할 수 있습니다.
특히 저의 경우, preseed.cfg를 수정하기 위해 인스톨러가 질의하는 것이 preseed.cfg의 어떤것과 대응이 되는지를 보기 위해 DEBCONF_DEBUG=5라는 옵션을 boot parameter로 주어야 했습니다. 이 때 사용할 수 있는 방법을 소개드립니다.
먼저 평소와 같이 ubuntu를 설치하기 위해 설치 이미지를 삽입합니다. 그 다음에는 언어를 선택하시면, 다음으로 넘어가기 전에 메뉴가 뜹니다.
이 상태에서 F6을 누르시면 옵션을 선택할 수 있고, 이 때 ESC키를 누르면 boot parameter가 하단에 보일 것입니다.</description></item><item><title>sudo를 password 없이 사용하기</title><link>http://kimmj.github.io/ubuntu/how-to-use-sudo-without-password/</link><pubDate>Wed, 08 Jan 2020 01:51:54 +0900</pubDate><guid>http://kimmj.github.io/ubuntu/how-to-use-sudo-without-password/</guid><description>/etc/sudoers는 sudo를 사용할 수 있는 파일입니다. 이 파일을 열어보면 다음과 같은 글이 적혀 있습니다.
Please consider adding local content in /etc/sudoers.d/ instead of directly modifying this file
즉, 직접 이 파일을 수정해서 sudo 권한을 주지 말고, /etc/sudoers.d/ 폴더 내에 파일을 추가하라는 의미입니다.
이 곳에는 /etc/sudoers와 마찬가지로 계정에 대한 설정을 추가할 수 있습니다. 그리고 /etc/sudoers에서는 &amp;ldquo;NOPASSWD&amp;quot;라는 옵션을 주어 password없이 타 계정의 권한을 가지게 만들 수 있습니다.
이 두가지를 종합하여 내 linux 계정이 sudo 명령어를 입력할 때, 즉 root 권한을 가지게 될 때 password를 입력하지 않도록 설정할 수 있습니다.</description></item></channel></rss>